import requests
import csv
import json
import time
import re
from html import escape
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet

# ==========================
# ğŸ”§ CONFIGURAÃ‡Ã•ES
# ==========================
repo = "CherryHQ/cherry-studio"
url = f"https://api.github.com/repos/{repo}/pulls"

# ğŸ‘‰ Adicione seu token para evitar limite de 60 requisiÃ§Ãµes/hora
# Gere em: https://github.com/settings/tokens
GITHUB_TOKEN = ""  # âš ï¸ Substitua pelo seu token pessoal

headers = {"Accept": "application/vnd.github.v3+json"}
if GITHUB_TOKEN:
    headers["Authorization"] = f"token {GITHUB_TOKEN}"

# ==========================
# ğŸ” COLETAR PRs FECHADOS
# ==========================
print(f"ğŸ” Coletando pull requests FECHADOS do repositÃ³rio {repo}...")

pulls = []
page = 1
max_prs = 300  # limite de seguranÃ§a (ajuste se quiser)

while len(pulls) < max_prs:
    params = {
        "state": "closed",
        "per_page": 100,
        "page": page,
        "sort": "updated",
        "direction": "desc"
    }
    response = requests.get(url, params=params, headers=headers)

    if response.status_code != 200:
        print(f"ğŸš« Erro {response.status_code}: {response.text}")
        break

    try:
        data_page = response.json()
    except ValueError:
        print(f"âš ï¸ Erro ao converter resposta da pÃ¡gina {page} em JSON.")
        break

    if not isinstance(data_page, list) or not data_page:
        print("ğŸ“­ Nenhum PR adicional encontrado.")
        break

    pulls.extend(data_page)
    print(f"ğŸ“„ PÃ¡gina {page} carregada ({len(data_page)} PRs). Total atÃ© agora: {len(pulls)}")
    page += 1
    time.sleep(0.4)

pulls = pulls[:max_prs]
print(f"âœ… Total de {len(pulls)} PRs fechados coletados.")

# ==========================
# ğŸ’¬ COLETAR COMENTÃRIOS
# ==========================
data = []

for i, pr in enumerate(pulls, start=1):
    comments_url = pr.get("comments_url")
    if not comments_url:
        continue

    try:
        comments_response = requests.get(comments_url, headers=headers, timeout=10)
        comments = comments_response.json()
    except Exception as e:
        print(f"âš ï¸ Erro ao buscar comentÃ¡rios do PR #{pr.get('number')}: {e}")
        comments = []

    all_comments = " | ".join(
        [c["body"].replace("\n", " ") for c in comments if "body" in c and c["body"]]
    )

    data.append({
        "PR_Number": pr.get("number"),
        "PR_Title": pr.get("title", ""),
        "Author": pr.get("user", {}).get("login", "Desconhecido"),
        "Created_At": pr.get("created_at", ""),
        "Closed_At": pr.get("closed_at", ""),
        "Comments": all_comments,
        "State": pr.get("state", "")
    })

    print(f"âœ… Processado {i}/{len(pulls)} PRs")
    time.sleep(0.2)

if not data:
    print("ğŸš« Nenhum dado coletado.")
    exit()

def clean_html(text):
    """Remove tags HTML problemÃ¡ticas e mantÃ©m links legÃ­veis."""
    if not text:
        return ""
    # Transforma <a href="url">texto</a> em 'texto (url)'
    text = re.sub(r'<a [^>]*href="([^"]+)"[^>]*>(.*?)</a>', r'\2 (\1)', text)
    # Remove qualquer outra tag HTML restante (img, span, etc.)
    text = re.sub(r"<[^>]+>", "", text)
    # Escapa caracteres especiais (<, >, &)
    return escape(text)

# ==========================
# ğŸ’¾ SALVAR JSON
# ==========================
with open("cherry_prs.json", "w", encoding="utf-8") as f_json:
    json.dump(data, f_json, indent=4, ensure_ascii=False)
print("ğŸ’¾ Arquivo JSON criado: cherry_prs.json")

# ==========================
# ğŸ’¾ SALVAR CSV
# ==========================
with open("cherry_prs.csv", "w", newline="", encoding="utf-8") as f_csv:
    writer = csv.DictWriter(f_csv, fieldnames=data[0].keys())
    writer.writeheader()
    writer.writerows(data)
print("ğŸ’¾ Arquivo CSV criado: cherry_prs.csv")

# ==========================
# ğŸ“„ GERAR PDF
# ==========================
pdf_filename = "cherry_prs.pdf"
doc = SimpleDocTemplate(pdf_filename, pagesize=A4)
styles = getSampleStyleSheet()
story = []

story.append(Paragraph(f"<b>Projeto:</b> {repo}", styles["Title"]))
story.append(Spacer(1, 12))
story.append(Paragraph(f"Lista dos Ãºltimos {len(data)} Pull Requests FECHADOS", styles["Heading2"]))
story.append(Spacer(1, 12))

for pr in data:
    comments_clean = clean_html(pr['Comments'])
    pr_info = f"""
    <b>PR #{pr['PR_Number']}</b>: {clean_html(pr['PR_Title'])}<br/>
    <b>Autor:</b> {clean_html(pr['Author'])}<br/>
    <b>Criado em:</b> {pr['Created_At']}<br/>
    <b>Fechado em:</b> {pr['Closed_At']}<br/>
    <b>ComentÃ¡rios:</b> {comments_clean[:500]}{'...' if len(comments_clean) > 500 else ''}<br/>
    <b>Estado:</b> {pr['State']}
    """
    story.append(Paragraph(pr_info, styles["Normal"]))
    story.append(Spacer(1, 12))

doc.build(story)
print(f"ğŸ“˜ Arquivo PDF criado: {pdf_filename}")
print("âœ… Finalizado com sucesso!")
